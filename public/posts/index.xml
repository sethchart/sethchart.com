<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Seth Chart</title>
    <link>https://sethchart.com/posts/</link>
    <description>Recent content in Posts on Seth Chart</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Seth ChartÂ© {year}</copyright>
    <lastBuildDate>Sun, 07 Mar 2021 11:37:13 -0500</lastBuildDate>
    
	<atom:link href="https://sethchart.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Index</title>
      <link>https://sethchart.com/posts/6/</link>
      <pubDate>Sun, 07 Mar 2021 11:37:13 -0500</pubDate>
      
      <guid>https://sethchart.com/posts/6/</guid>
      <description>What You Will Learn In this post I will show you how to set up a Jupyter notebook server in a Docker container. There are three major benefits that you can expect from this approach.
 Setting up a new environment is fast! Resetting your environment is easy! Tools that you install while working on your project are separated from you computer so cleaning up after a project is easy.  Prerequisites To follow along with this blog post you will need to install Docker on your computer.</description>
    </item>
    
    <item>
      <title>Adding Lemmatization to CountVectorizer Without Making a Mess</title>
      <link>https://sethchart.com/posts/5/</link>
      <pubDate>Sun, 21 Feb 2021 12:57:33 -0500</pubDate>
      
      <guid>https://sethchart.com/posts/5/</guid>
      <description>Background This past week, I have been working on refactoring some of the code for my DataJobs project. That project explores the relationship between job descriptions and job titles in the data industry using natural language processing techniques. In particular, the DataJobs project uses Latent Dirichlet Allocation to detect topics within job descriptions. In this post, I am going to focus on data preprocessing for LDA and how to implement it in a scikit-learn pipeline.</description>
    </item>
    
    <item>
      <title>Latent Dirichlet Allocation</title>
      <link>https://sethchart.com/posts/4/</link>
      <pubDate>Sun, 14 Feb 2021 13:24:44 -0500</pubDate>
      
      <guid>https://sethchart.com/posts/4/</guid>
      <description>An Example In one of my recent projects I wanted to investigate job postings for jobs in the data industry. In the data industry, it is widely believed that job titles are not a reliable indicator of the role that they describe. The title Data Scientist may describe two completely different roles depending on the company. Similarly, nearly identical roles might have the job title Data Scientist in one company and Data Analyst in another company.</description>
    </item>
    
    <item>
      <title>How I Scraped Job Postings from Careerjet</title>
      <link>https://sethchart.com/posts/3/</link>
      <pubDate>Tue, 26 Jan 2021 08:53:31 -0500</pubDate>
      
      <guid>https://sethchart.com/posts/3/</guid>
      <description>What You Will Learn Do you want to do some natural language processing on job postings and need data? That was my situation about a month ago when I was starting my capstone project for my Data Science bootcamp at Flatiron school. I found that careerjet.com had fairly straightforward web design and over three million job postings in the United States, a great candidate for web scraping! In this post, I will describe my approach to scraping careerjet.</description>
    </item>
    
    <item>
      <title>Demystifying ARMA Models</title>
      <link>https://sethchart.com/posts/2/</link>
      <pubDate>Wed, 23 Dec 2020 17:28:40 -0500</pubDate>
      
      <guid>https://sethchart.com/posts/2/</guid>
      <description>Last week, I finished a project where I identified the five zip codes, in the city of Baltimore, where an individual would expect the highest return on investment if they bought a house, lived in it for two years and then sold it and moved away. You can check out my GitHub repository for the project here. I used Seasonal AutoRegressive Integrated Moving Average (SARIMA) models to forecast house prices based on historical data that I collected from Zillow.</description>
    </item>
    
    <item>
      <title>Pump it Up: Data Mining the Water Table</title>
      <link>https://sethchart.com/posts/1/</link>
      <pubDate>Fri, 06 Nov 2020 20:52:31 -0500</pubDate>
      
      <guid>https://sethchart.com/posts/1/</guid>
      <description>Project Description In this post, I will tell you about building my submission to the Pump it Up: Data Mining the Water Table competition hosted by DrivenData. The competition problem uses data about water pumps in Tanzania collected by a partnership between Taarifa and the United Republic of Tanzania Ministry of Water to predict if they are currently in need of repair. Specifically, the goal is to classify a water pump as &amp;lsquo;functional&amp;rsquo;, &amp;lsquo;functional needs repair&amp;rsquo;, or &amp;lsquo;non functional&amp;rsquo; given the available data.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://sethchart.com/posts/0/</link>
      <pubDate>Fri, 23 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://sethchart.com/posts/0/</guid>
      <description>A Long Story Shortened My name is Seth Chart. I am, in order of decreasing experience, a son, brother, mathematician, teacher, husband, feline personal assistant, database manager, python programmer, web development hobbyist, data scientist, and blogger.
Biography The Early Years I grew up in Utah. My Father is a Fisheries Biologist who has spent his career working to protect endangered fish species in the western United States. Most of my early memories were formed when we lived in Moab, Utah, where he managed a research field station.</description>
    </item>
    
  </channel>
</rss>